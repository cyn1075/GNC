{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f736dd44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd178969-9cde-4301-8818-bb23a7a1ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openpyxl\n",
    "pip install torch torchvision torchaudio\n",
    "pip install dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe6ba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import dill\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metric\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fd1b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AutoEncoder 학습을 위한 클래스\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.AutoEncoder = nn.Sequential(\n",
    "        \n",
    "        nn.Linear(input_size, hidden_size[0]),\n",
    "        nn.RReLU(),\n",
    "        \n",
    "        nn.Linear(hidden_size[0], output_size),\n",
    "        nn.RReLU(),\n",
    "        \n",
    "        nn.Linear(output_size, hidden_size[0]),\n",
    "        nn.RReLU(),\n",
    "        nn.Linear(hidden_size[0], input_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        output = self.AutoEncoder(inputs)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509ee4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 함수 정의\n",
    "def train_net(AutoEncoder, data, criterion, epochs, lr, batch_size, optimizer):\n",
    "    optim = optimizer(AutoEncoder.parameters(), lr = lr)\n",
    "    data_iter = DataLoader(data, batch_size = batch_size, shuffle = True)\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        running_loss = 0.0\n",
    "        for x in data_iter:\n",
    "            optim.zero_grad()\n",
    "            output = AutoEncoder(x)\n",
    "            \n",
    "            loss = criterion(x, output)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        print(\"epoch: {}, loss: {:2f}\".format(epoch, running_loss))\n",
    "                \n",
    "    return AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cb5e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 입력, 전처리 함수\n",
    "def preprocess_data(file_path):\n",
    "    welding_data = pd.read_excel(file_path, index_col='idx')\n",
    "\n",
    "    new_welding_data = welding_data.iloc[:, 5:]\n",
    "\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    scaler.fit(new_welding_data)\n",
    "    scaled_data = scaler.transform(new_welding_data)\n",
    "    \n",
    "    split_index = int(len(scaled_data) * 0.8)\n",
    "\n",
    "    train_data = torch.Tensor(scaled_data[:split_index])\n",
    "    test_data = torch.Tensor(scaled_data[split_index:])\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834099de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = preprocess_data('파일 이름 넣기')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c25aad-fb00-439c-83ef-770172676819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_data(train_data):\n",
    "    epoch = 50\n",
    "    batch_size = 64\n",
    "    lr = 0.01\n",
    "\n",
    "    input_size = len(train_data[0])\n",
    "    hidden_size = [3]\n",
    "    output_size = 2\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam\n",
    "    \n",
    "    define_AutoEncoder = AutoEncoder(input_size, hidden_size, output_size)\n",
    "    \n",
    "    train_AutoEncoder = train_net(define_AutoEncoder, train_data, criterion, epoch, lr, batch_size, optimizer)\n",
    "\n",
    "    # model_filepath = 'model.pt'\n",
    "    # save_model(train_AutoEncoder, model_filepath)\n",
    "    return train_AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221acbcb-7e3c-4172-b117-a5b079f1f602",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894aa564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 학습 함수\n",
    "# epoch - 데이터셋을 학습하는 횟수\n",
    "# batchSize - 데이터를 몇개의 그룹으로 나눌것인지 정한다.\n",
    "# lr - 모델 가중치를 조절\n",
    "# 모델 저장 함수\n",
    "def save_model(model, filepath):\n",
    "    torch.save(model, filepath)\n",
    "\n",
    "\n",
    "def training_data(train_data):\n",
    "    epoch = 50\n",
    "    batch_size = 64\n",
    "    lr = 0.01\n",
    "\n",
    "    input_size = len(train_data[0])\n",
    "    hidden_size = [3]\n",
    "    output_size = 2\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam\n",
    "    \n",
    "    define_AutoEncoder = AutoEncoder(input_size, hidden_size, output_size)\n",
    "    \n",
    "    train_AutoEncoder = train_net(define_AutoEncoder, train_data, criterion, epoch, lr, batch_size, optimizer)\n",
    "\n",
    "    model_filepath = 'model.pt'\n",
    "    save_model(train_AutoEncoder, model_filepath)\n",
    "    \n",
    "training_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f61aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장 데이터 불러오기\n",
    "# 파일 이름과 저장되있는 주소 값 넣기\n",
    "def load_model(file_name):\n",
    "    model = torch.load(file_name, pickle_module = dill)\n",
    "    return model\n",
    "\n",
    "model = load_model('./model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebd377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(outlier):\n",
    "    df = pd.DataFrame(outlier, columns=['result'])\n",
    "    df.to_excel('결과.xlsx', index=True)\n",
    "    \n",
    "# 결과출력 함수\n",
    "def result_data(model, train_data):\n",
    "    criterion = nn.MSELoss()\n",
    "    train_loss_chart = []\n",
    "    for data in train_data:\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data)\n",
    "        train_loss_chart.append(loss.item())\n",
    "    \n",
    "    threshold = np.mean(train_loss_chart) + np.std(train_loss_chart)*8\n",
    "    print(\"임계값 :\", threshold)\n",
    "\n",
    "    test_loss_chart = []\n",
    "    for data in train_data:\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data)\n",
    "        test_loss_chart.append(loss.item())\n",
    "\n",
    "\n",
    "    outlier = list(test_loss_chart >= threshold)\n",
    "    print(\"불량 개수 :\", outlier.count(True))\n",
    "     \n",
    "    return save_file(outlier)\n",
    "    \n",
    "def save_file(outlier)\n",
    "    df = pd.DataFrame(outlier, columns=['result'])\n",
    "    df.to_excel('결과.xlsx', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ed4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data(model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9693d22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
